{
  "hash": "ea94189f8887a2c2b498891319f6ce61",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"2 La régression linéaire multiple\"\ntoc: true\n---\n\n::: {#9ff80708 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n```\n:::\n\n\n#   La concentration en ozone\n\n::: {#80a92453 .cell execution_count=2}\n``` {.python .cell-code}\nozone = pd.read_csv(\"../donnees/ozone.txt\", header=0, sep=\";\")\n```\n:::\n\n\n::: {#b5bf6b26 .cell execution_count=3}\n``` {.python .cell-code}\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(ozone.T12, ozone.Vx,ozone.O3)\nax.set_xlabel('T12') ; ax.set_ylabel('Vx') ; ax.set_zlabel('O3')\nfig.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](chap2_files/figure-html/cell-4-output-1.png){width=488 height=473}\n:::\n:::\n\n\n::: {#3a81554c .cell execution_count=4}\n``` {.python .cell-code}\nreg = smf.ols('O3 ~ T12+Vx', data=ozone).fit()\nreg.summary()\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>           <td>O3</td>        <th>  R-squared:         </th> <td>   0.525</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.505</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   25.96</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Fri, 31 Jan 2025</td> <th>  Prob (F-statistic):</th> <td>2.54e-08</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>17:30:04</td>     <th>  Log-Likelihood:    </th> <td> -210.53</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   427.1</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   432.8</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>Intercept</th> <td>   35.4530</td> <td>   10.745</td> <td>    3.300</td> <td> 0.002</td> <td>   13.838</td> <td>   57.068</td>\n</tr>\n<tr>\n  <th>T12</th>       <td>    2.5380</td> <td>    0.515</td> <td>    4.927</td> <td> 0.000</td> <td>    1.502</td> <td>    3.574</td>\n</tr>\n<tr>\n  <th>Vx</th>        <td>    0.8736</td> <td>    0.177</td> <td>    4.931</td> <td> 0.000</td> <td>    0.517</td> <td>    1.230</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td> 0.280</td> <th>  Durbin-Watson:     </th> <td>   1.678</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.869</td> <th>  Jarque-Bera (JB):  </th> <td>   0.331</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td> 0.165</td> <th>  Prob(JB):          </th> <td>   0.848</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 2.777</td> <th>  Cond. No.          </th> <td>    94.4</td>\n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n:::\n:::\n\n\n#   La hauteur des eucalyptus\n\n::: {#ae309f56 .cell execution_count=5}\n``` {.python .cell-code}\neucalyptus = pd.read_csv(\"../donnees/eucalyptus.txt\",header=0,sep=\";\")\nfig = plt.figure()\nplt.plot(eucalyptus.circ, eucalyptus.ht, '+k')\nplt.ylabel('ht') ; plt.xlabel('circ')\nfig.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](chap2_files/figure-html/cell-6-output-1.png){width=661 height=468}\n:::\n:::\n\n\n::: {#4d72ad12 .cell execution_count=6}\n``` {.python .cell-code}\nreg = smf.ols('ht ~ circ+np.sqrt(circ)', data=eucalyptus).fit()\nreg.summary()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>           <td>ht</td>        <th>  R-squared:         </th> <td>   0.792</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.792</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2718.</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Fri, 31 Jan 2025</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n</tr>\n<tr>\n  <th>Time:</th>                 <td>17:30:04</td>     <th>  Log-Likelihood:    </th> <td> -2208.5</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>  1429</td>      <th>  AIC:               </th> <td>   4423.</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>  1426</td>      <th>  BIC:               </th> <td>   4439.</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>Intercept</th>     <td>  -24.3520</td> <td>    2.614</td> <td>   -9.314</td> <td> 0.000</td> <td>  -29.481</td> <td>  -19.223</td>\n</tr>\n<tr>\n  <th>circ</th>          <td>   -0.4829</td> <td>    0.058</td> <td>   -8.336</td> <td> 0.000</td> <td>   -0.597</td> <td>   -0.369</td>\n</tr>\n<tr>\n  <th>np.sqrt(circ)</th> <td>    9.9869</td> <td>    0.780</td> <td>   12.798</td> <td> 0.000</td> <td>    8.456</td> <td>   11.518</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td> 3.015</td> <th>  Durbin-Watson:     </th> <td>   0.947</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.221</td> <th>  Jarque-Bera (JB):  </th> <td>   2.897</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td>-0.097</td> <th>  Prob(JB):          </th> <td>   0.235</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 3.103</td> <th>  Cond. No.          </th> <td>4.41e+03</td>\n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.41e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.\n```\n:::\n:::\n\n\n::: {#78ef7dc7 .cell execution_count=7}\n``` {.python .cell-code}\ngrille = pd.DataFrame({'circ' : np.linspace(eucalyptus.circ.min(), \\\n                            eucalyptus.circ.max(),100)})\ncalculprev = reg.get_prediction(grille)\nprev = calculprev.predicted_mean\n\nfig = plt.figure()\nplt.plot(eucalyptus.circ, eucalyptus.ht, '+k')\nplt.ylabel('ht') ; plt.xlabel('circ')\nplt.plot(grille.circ, prev, '-', lw=1)\nfig.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](chap2_files/figure-html/cell-8-output-1.png){width=661 height=468}\n:::\n:::\n\n\n",
    "supporting": [
      "chap2_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}