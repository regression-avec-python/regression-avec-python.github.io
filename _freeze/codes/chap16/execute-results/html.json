{
  "hash": "72da68d5d139b0121a6779983ec7491e",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"16 Données déséquilibrées\"\ntoc: true\n---\n\n::: {#2186fd69 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd; import numpy as np\nimport matplotlib.pyplot as plt\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LogisticRegression,\\\n    LogisticRegressionCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedKFold\nfrom imblearn.under_sampling import RandomUnderSampler, TomekLinks\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE\nfrom sklearn.metrics import accuracy_score, f1_score, \\\n    balanced_accuracy_score, cohen_kappa_score, roc_auc_score\nimport sklearn.metrics as sklm\n```\n:::\n\n\n#   Données déséquilibrées et modèle logistique\n\n::: {#50252a1d .cell execution_count=2}\n``` {.python .cell-code}\nrng = np.random.default_rng(seed=1234)\nn=200\nN=1000\nbeta1_m1 = np.repeat(0.0, N)\nbeta2_m1 = np.repeat(0.0, N)\nbeta1_m2 = np.repeat(0.0, N)\nbeta2_m2 = np.repeat(0.0, N)\nfor k in range(0,N):\n    X = rng.uniform(0,1,n)\n    Z1 = 3 - 6*X\n    Z2 = -1 - 6*X\n    p1 = np.exp(Z1)/(1+np.exp(Z1))\n    p2 = np.exp(Z2)/(1+np.exp(Z2))\n    Y1 = np.repeat(0,n)\n    Y2 = np.repeat(0,n)\n    for i in range(0,n):\n        Y1[i] = rng.binomial(1, p1[i], size=1)[0]\n        Y2[i] = rng.binomial(1, p2[i], size=1)[0]\n    df=pd.DataFrame({\"X\": X, \"Y1\": Y1, \"Y2\": Y2})\n    mod1 = smf.glm(\"Y1~1+X\", data=df, family=sm.families.Binomial()).fit()\n    mod2 = smf.glm(\"Y2~1+X\", data=df, family=sm.families.Binomial()).fit()\n    beta1_m1[k] = mod1.params.Intercept - 3\n    beta2_m1[k] = mod1.params.X + 6\n    beta1_m2[k] = mod2.params.Intercept + 1\n    beta2_m2[k] = mod2.params.X + 6\n\n\nlabels = [\"mod1\", \"mod2\"]\nfig, (ax1, ax2) = plt.subplots(1,2)\nax1.boxplot([beta1_m1, beta1_m2], tick_labels=labels, widths=0.6)\nax1.set_ylim(-6.5,6.5)\nax1.axhline(0, linestyle='dashed')\nax1.set_title('intercept', {'fontweight': \"bold\", 'fontsize': 7})\nax2.boxplot([beta2_m1, beta2_m2], tick_labels=labels, widths=0.6)\nax2.set_ylim(-6.5,6.5)\nax2.axhline(0, linestyle='dashed')\nax2.set_title(\"slope\", {'fontweight': \"bold\", 'fontsize': 7})\nfig.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](chap16_files/figure-html/cell-3-output-1.png){width=662 height=470}\n:::\n:::\n\n\n::: {#10a67a5d .cell execution_count=3}\n``` {.python .cell-code}\nrng = np.random.default_rng(seed=1234)\nn=200\nN=1000\nbeta1_m2 = np.repeat(0.0, N)\nbeta2_m2 = np.repeat(0.0, N)\nbeta1_m3 = np.repeat(0.0, N)\nbeta2_m3 = np.repeat(0.0, N)\nfor k in range(0,N):\n    X = rng.uniform(0,1,n)\n    Z2 = -1 - 6*X\n    p2 = np.exp(Z2)/(1+np.exp(Z2))\n    Y2 = np.repeat(0,n)\n    Y3 = np.repeat(0,n)\n    for i in range(0,n):\n        s = 0\n        Y2[i] = rng.binomial(1, p2[i], size=1)[0]\n        while (s==0):\n            Y3[i] = rng.binomial(1, p2[i], size=1)[0]\n            tau = Y3[i]*0.95 + (1-Y3[i])*0.05\n            s = rng.binomial(1, tau, size=1)[0]\n    df=pd.DataFrame({\"X\": X, \"Y2\": Y2, \"Y3\": Y3})\n    mod2 = smf.glm(\"Y2~1+X\", data=df, family=sm.families.Binomial()).fit()\n    mod3 = smf.glm(\"Y3~1+X\", data=df, family=sm.families.Binomial()).fit()\n    beta1_m2[k] = mod2.params.Intercept + 1\n    beta2_m2[k] = mod2.params.X + 6\n    beta1_m3[k] = mod3.params.Intercept + 1\n    beta2_m3[k] = mod3.params.X + 6\n\n\n\nplt.rcParams.update({\"text.usetex\": True})\nlabels = [r\"$\\hat\\beta$\", r\"$\\hat\\gamma$\"]\nfig, (ax1, ax2) = plt.subplots(1,2)\nax1.boxplot([beta1_m2, beta1_m3], tick_labels=labels, widths=0.6)\nax1.set_ylim(-6,6)\nax1.axhline(0, linestyle='dashed')\nax1.set_title('intercept', {'fontweight': \"bold\", 'fontsize': 7})\nax2.boxplot([beta2_m2, beta2_m3], tick_labels=labels, widths=0.6)\nax2.set_ylim(-6.8,6)\nax2.axhline(0, linestyle='dashed')\nax2.set_title(\"slope\", {'fontweight': \"bold\", 'fontsize': 7})\nfig.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](chap16_files/figure-html/cell-4-output-1.png){width=662 height=470}\n:::\n:::\n\n\n::: {#55e4205a .cell execution_count=4}\n``` {.python .cell-code}\nplt.rcParams.update({\"text.usetex\": True})\nbeta1_m3cor = beta1_m3 - np.log(0.95/0.05)\nlabels = [r\"$\\hat\\beta_1$\", r\"$\\hat\\gamma_1$\", r\"$\\hat\\gamma_{1,\\mbox{cor}}$\"]\nfig, ax1 = plt.subplots(1,1)\nax1.boxplot([beta1_m2, beta1_m3, beta1_m3cor], tick_labels=labels, widths=0.5)\nax1.set_ylim(-6,6)\nax1.axhline(0, linestyle='dashed')\n```\n\n::: {.cell-output .cell-output-display}\n![](chap16_files/figure-html/cell-5-output-1.png){width=566 height=418}\n:::\n:::\n\n\n::: {#948376a5 .cell execution_count=5}\n``` {.python .cell-code}\ndf = pd.DataFrame({\"MALADE\": [208, 42], \"NON_MALADE\": [48, 202], \"FUMEUR\": [\"OUI\", \"NON\"]})\nmodel = smf.glm(\"MALADE+NON_MALADE~FUMEUR\", data=df, family=sm.families.Binomial()).fit()\nround(model.params,3)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\nIntercept       -1.571\nFUMEUR[T.OUI]    3.037\ndtype: float64\n```\n:::\n:::\n\n\n::: {#b765b9e6 .cell execution_count=6}\n``` {.python .cell-code}\nnewX=pd.DataFrame({\"FUMEUR\": [\"OUI\", \"NON\"]})\nmodel.predict(newX)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n0    0.812500\n1    0.172131\ndtype: float64\n```\n:::\n:::\n\n\n::: {#65cd7860 .cell execution_count=7}\n``` {.python .cell-code}\nbeta1_cor = model.params.iloc[0] - np.log(0.995/0.005)\nbeta2 = model.params.iloc[1]\nround((np.exp(beta1_cor+beta2)/(1+np.exp(beta1_cor+beta2))),3)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n0.021\n```\n:::\n:::\n\n\n::: {#aeec8432 .cell execution_count=8}\n``` {.python .cell-code}\nround((np.exp(beta1_cor)/(1+np.exp(beta1_cor))),3)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n0.001\n```\n:::\n:::\n\n\n::: {#3a15a7c4 .cell execution_count=9}\n``` {.python .cell-code}\nr = 1\nrus = RandomUnderSampler(sampling_strategy=r, random_state=0)\nX_r, y_r = rus.fit_resample(X, y)\ndfr = pd.DataFrame(X_r).assign(y_r = y_r)\n```\n:::\n\n\n::: {#5f421af2 .cell execution_count=10}\n``` {.python .cell-code}\nmod=smf.glm(\"y_r~...\",data=dfr,family=sm.families.Binomial()).fit()\n```\n:::\n\n\n::: {#4f3e5838 .cell execution_count=11}\n``` {.python .cell-code}\nn1 = df.Y.value_counts()[1]\ngamma = model.params\ngamma[0] - log(n1*r)\n```\n:::\n\n\n#   Stratégies pour données déséquilibrées\n\n##  Quelques méthodes de rééquilibrages\n\n::: {#de923002 .cell execution_count=12}\n``` {.python .cell-code}\ndf = pd.read_csv('../donnees/dd_ex_ech_des1.csv', header=0, sep=';')\ndf.Y.value_counts()\ny = df.Y\nX = df.loc[:,[\"X1\", \"X2\"]]\n```\n:::\n\n\n::: {#0449cba2 .cell execution_count=13}\n``` {.python .cell-code}\nfig = plt.figure()\nplt.plot(df.loc[df.Y==0, \"X1\"], df.loc[df.Y==0, \"X2\"], 'o', df.loc[df.Y==1, \"X1\"], df.loc[df.Y==1, \"X2\"], '^')\nfig.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](chap16_files/figure-html/cell-14-output-1.png){width=662 height=470}\n:::\n:::\n\n\n::: {#496d91dc .cell execution_count=14}\n``` {.python .cell-code}\nros1 = RandomOverSampler(random_state=0)\nXreech1, yreech1 = ros1.fit_resample(X, y)\nprint(yreech1.value_counts())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nY\n0    80\n1    80\nName: count, dtype: int64\n```\n:::\n:::\n\n\n::: {#219c98a8 .cell execution_count=15}\n``` {.python .cell-code}\nros2 = RandomOverSampler(random_state=0, sampling_strategy={0: 80, 1: 40})\nXreech2, yreech2 = ros2.fit_resample(X, y)\nprint(yreech2.value_counts())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nY\n0    80\n1    40\nName: count, dtype: int64\n```\n:::\n:::\n\n\n::: {#c0f69e47 .cell execution_count=16}\n``` {.python .cell-code}\nover1 = pd.DataFrame(Xreech1)\nover1[\"Y\"] = yreech1\n```\n:::\n\n\n::: {#c711aa42 .cell execution_count=17}\n``` {.python .cell-code}\nsmote1 = SMOTE(random_state=42, k_neighbors=4)\nXreech1, yreech1 = smote1.fit_resample(X, y)\nprint(yreech1.value_counts())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nY\n0    80\n1    80\nName: count, dtype: int64\n```\n:::\n:::\n\n\n::: {#ee3e65b6 .cell execution_count=18}\n``` {.python .cell-code}\nsmote2 = SMOTE(random_state=423, k_neighbors=4, \\\n               sampling_strategy={0: 80, 1: 40})\nXreech2, yreech2 = smote2.fit_resample(X, y)\nprint(yreech2.value_counts())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nY\n0    80\n1    40\nName: count, dtype: int64\n```\n:::\n:::\n\n\n::: {#29b6306f .cell execution_count=19}\n``` {.python .cell-code}\ndf1 = Xreech1.assign(Yreech = yreech1)\ntmp = df1.merge(df, how=\"outer\", on=['X1', 'X2'])\nnouv1 = tmp.loc[tmp.Y.isna(), :]\nnouv1.Yreech.value_counts()\n\n\ndf2 = Xreech2.assign(Yreech = yreech2)\ntmp = df2.merge(df, how=\"outer\", on=['X1', 'X2'])\nnouv2 = tmp.loc[tmp.Y.isna(), :]\nnouv2.Yreech.value_counts()\n\n\nplt.rc(\"lines\", markersize=2)\ncoul = [\"C0\", \"C1\"]\nmark = [\"^\", \"o\"]\nfig, (ax1, ax2) = plt.subplots(1,2)\nfor i in range(0,2):\n    ax1.plot(df.loc[df.Y==i, \"X1\"], df.loc[df.Y==i, \"X2\"], marker=mark[i], c=coul[i], ls='')\n    ax1.plot(nouv1.loc[nouv1.Yreech==i, \"X1\"], nouv1.loc[nouv1.Yreech==i, \"X2\"], marker=mark[i], c=coul[i], ls='')\n    ax1.plot(nouv1.loc[nouv1.Yreech==i, \"X1\"], nouv1.loc[nouv1.Yreech==i, \"X2\"],\\\n             marker = mark[1], ms=8, mec=coul[i], mfc='#ffffff00', ls='')\n    ax2.plot(df.loc[df.Y==i, \"X1\"], df.loc[df.Y==i, \"X2\"], marker=mark[i], c=coul[i], ls='')\n    ax2.plot(nouv2.loc[nouv2.Yreech==i, \"X1\"], nouv2.loc[nouv2.Yreech==i, \"X2\"], marker=mark[i], c=coul[i], ls='')\n    ax2.plot(nouv2.loc[nouv2.Yreech==i, \"X1\"], nouv2.loc[nouv2.Yreech==i, \"X2\"],\\\n             marker = mark[1], ms=8, mec=coul[i], mfc=\"#ffffff00\", ls='')\n\nfig.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](chap16_files/figure-html/cell-20-output-1.png){width=660 height=470}\n:::\n:::\n\n\n::: {#4d10f3c9 .cell execution_count=20}\n``` {.python .cell-code}\ny = df.Y\nX = df.loc[:,[\"X1\", \"X2\"]]\nrus1 = RandomUnderSampler(random_state=38)\nXreech1, yreech1 = rus1.fit_resample(X, y)\nprint(yreech1.value_counts())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nY\n0    20\n1    20\nName: count, dtype: int64\n```\n:::\n:::\n\n\n::: {#ad980323 .cell execution_count=21}\n``` {.python .cell-code}\nrus2 = RandomUnderSampler(random_state=38, sampling_strategy={0: 40, 1: 20})\nXreech2, yreech2 = rus2.fit_resample(X, y)\nprint(yreech2.value_counts())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nY\n0    40\n1    20\nName: count, dtype: int64\n```\n:::\n:::\n\n\n::: {#024ea87c .cell execution_count=22}\n``` {.python .cell-code}\ntl1 = TomekLinks(sampling_strategy='all')\nXreech1, yreech1 = tl1.fit_resample(X, y)\nprint(yreech1.value_counts())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nY\n0    76\n1    16\nName: count, dtype: int64\n```\n:::\n:::\n\n\n::: {#010e85af .cell execution_count=23}\n``` {.python .cell-code}\ntl2 = TomekLinks(sampling_strategy='majority')\nXreech2, yreech2 = tl2.fit_resample(X, y)\nprint(yreech2.value_counts())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nY\n0    76\n1    20\nName: count, dtype: int64\n```\n:::\n:::\n\n\n::: {#469e47a9 .cell execution_count=24}\n``` {.python .cell-code}\ndf1 = Xreech1.assign(Yreech = yreech1)\ntmp = df.merge(df1, how=\"outer\", on=['X1', 'X2'])\nnouv1 = tmp.loc[tmp.Yreech.isna(), :]\nnouv1.Y.value_counts()\n\ndf2 = Xreech2.assign(Yreech = yreech2)\ntmp = df.merge(df2, how=\"outer\", on=['X1', 'X2'])\nnouv2 = tmp.loc[tmp.Yreech.isna(), :]\nnouv2.Y.value_counts()\n\n\nplt.rc(\"lines\", markersize=3)\ncoul = [\"C0\", \"C1\"]\nmark = [\"^\", \"o\"]\nfig, (ax1, ax2) = plt.subplots(1,2)\nfor i in range(0,2):\n    ax1.plot(df.loc[df.Y==i, \"X1\"], df.loc[df.Y==i, \"X2\"], marker=mark[i], c=coul[i], ls='')\n    ax1.plot(nouv1.loc[nouv1.Y==i, \"X1\"], nouv1.loc[nouv1.Y==i, \"X2\"], marker=mark[i], c=coul[i], ls='')\n    ax1.plot(nouv1.loc[nouv1.Y==i, \"X1\"], nouv1.loc[nouv1.Y==i, \"X2\"],\\\n             marker = mark[1], ms=8, mec=coul[i], mfc='#ffffff00', ls='')\n    ax2.plot(df.loc[df.Y==i, \"X1\"], df.loc[df.Y==i, \"X2\"], marker=mark[i], c=coul[i], ls='')\n    ax2.plot(nouv2.loc[nouv2.Y==i, \"X1\"], nouv2.loc[nouv2.Y==i, \"X2\"], marker=mark[i], c=coul[i], ls='')\n    ax2.plot(nouv2.loc[nouv2.Y==i, \"X1\"], nouv2.loc[nouv2.Y==i, \"X2\"],\\\n             marker = mark[1], ms=8, mec=coul[i], mfc=\"#ffffff00\", ls='')\n\nfig.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](chap16_files/figure-html/cell-25-output-1.png){width=660 height=470}\n:::\n:::\n\n\n::: {#3dda0dfa .cell execution_count=25}\n``` {.python .cell-code}\ncoul = [\"C0\", \"C1\"]\nmark = [\"^\", \"o\"]\nfig, (ax1, ax2) = plt.subplots(1,2)\nfor i in range(0,2):\n    ax1.plot(df1.loc[df1.Yreech==i, \"X1\"], df1.loc[df1.Yreech==i, \"X2\"], marker=mark[i], c=coul[i], ls='')\n    ax2.plot(df2.loc[df2.Yreech==i, \"X1\"], df2.loc[df2.Yreech==i, \"X2\"], marker=mark[i], c=coul[i], ls='')\n\nfig.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](chap16_files/figure-html/cell-26-output-1.png){width=660 height=470}\n:::\n:::\n\n\n##  Critères pour données déséquilibrées\n\n::: {#3cfd48ed .cell execution_count=26}\n``` {.python .cell-code}\ndf = pd.read_csv(\"../donnees/donnees_dondesequilib.csv\", header=0, sep=';')\nprint(pd.crosstab(index=df.Y, columns=df.P1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nP1    0  1\nY         \n0   468  0\n1    31  1\n```\n:::\n:::\n\n\n::: {#9f48abef .cell execution_count=27}\n``` {.python .cell-code}\nprint(pd.crosstab(index=df.Y, columns=df.P2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nP2    0   1\nY          \n0   407  61\n1     4  28\n```\n:::\n:::\n\n\n::: {#565a6ffa .cell execution_count=28}\n``` {.python .cell-code}\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, cohen_kappa_score\nprint(np.round(accuracy_score(df.Y, df.P2), 3))\nprint(np.round(balanced_accuracy_score(df.Y, df.P2), 3))\nprint(np.round(f1_score(df.Y, df.P2), 3))\nprint(np.round(cohen_kappa_score(df.Y, df.P2), 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.87\n0.872\n0.463\n0.407\n```\n:::\n:::\n\n\n#  Choisir un algortihme de rééquilibrage\n\n::: {#33b3acf8 .cell execution_count=29}\n``` {.python .cell-code}\nad = pd.read_csv(\"../donnees/ad_data.txt\", header=None ,sep=\",\",\\\n                 na_values = \"?\", skipinitialspace=True, keep_default_na=True)\nnoms = [\"X\" + str(i+1) for i in range(ad.shape[1] - 1)]\nnoms.append(\"Y\")\nad.columns = noms\nad1 = ad.dropna(axis=1)\nad1.loc[:,\"Y\"] = ad1[\"Y\"].astype(\"category\").cat.rename_categories({\"nonad.\": 0, \"ad.\": 1})\nX =  ad1.iloc[:,:-1]\ny = pd.to_numeric(ad1.iloc[:,-1])\nad1.Y.value_counts()\n```\n\n::: {.cell-output .cell-output-display execution_count=26}\n```\nY\n0    2820\n1     459\nName: count, dtype: int64\n```\n:::\n:::\n\n\n::: {#8503b941 .cell execution_count=30}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import StandardScaler\ndef grille(X, y, type = \"lasso\", ng=400):\n    \"\"\"\n    X: tableau des var explicatives au format sklearn\n    y: variable a expliquer au format sklearn\n    type: \"lasso\" ou \"ridge\" ou \"enet\"\n    ng: nombre de valeur dans le chemin\n\n    retourne la grille\n    \"\"\"\n    scalerX = StandardScaler().fit(X)\n    Xcr= scalerX.transform(X)\n    l0 = np.abs(Xcr.transpose().dot((y  - y.mean()))).max()/X.shape[0]\n    llc = np.linspace(0,-4,ng)\n    ll = l0*10**llc\n    if type==\"lasso\":\n        Cs = 1/ 0.9/ X.shape[0] / (l0*10**(llc))\n    elif type==\"ridge\":\n        Cs = 1/ 0.9/ X.shape[0] / ((l0*10**(llc)) * 100)\n    elif type==\"enet\":\n        Cs = 1/ 0.9/ X.shape[0] / ((l0*10**(llc)) * 2)\n    return Cs\n```\n:::\n\n\n::: {#45ead886 .cell execution_count=31}\n``` {.python .cell-code}\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\nRES = pd.DataFrame(pd.to_numeric(ad1.iloc[:,ad1.shape[1]-1]))\nfor i in [\"Logistic\", \"Lasso\", \"Ridge\"]:\n    for j in [\"brut\", \"ros\", \"smote\", \"rus\", \"tomek\"]:\n        RES = RES.assign(**{i + \"_\" + j: 0})\n```\n:::\n\n\n::: {#755bf86d .cell execution_count=32}\n``` {.python .cell-code}\nfor app_index, val_index in skf.split(X,y):\n    Xapp = X.iloc[app_index,:-1]\n    yapp = y.iloc[app_index]\n    Xval = X.iloc[val_index,:-1]\n    # grille\n    Cs_lasso = grille(Xapp, yapp, \"lasso\")\n    Cs_ridge = grille(Xapp, yapp, \"ridge\")\n    # instanciation\n    cr = StandardScaler()\n    logistic =  LogisticRegression(penalty=None, solver=\"newton-cholesky\" )\n    lassocv =  LogisticRegressionCV(cv=10, penalty=\"l1\", n_jobs=10, Cs=Cs_lasso,  solver=\"saga\", max_iter=2000)\n    ridgecv = LogisticRegressionCV(cv=10, penalty=\"l2\", n_jobs=10, Cs=Cs_ridge,  max_iter=1000)\n    pipe_logistic = Pipeline(steps=[(\"cr\", cr), (\"logistic\", logistic)])\n    pipe_lassocv = Pipeline(steps=[(\"cr\", cr), (\"lassocv\", lassocv)])\n    pipe_ridgecv = Pipeline(steps=[(\"cr\", cr), (\"ridgecv\", ridgecv)])\n    # fit brut\n    pipe_logistic.fit(Xapp, yapp)\n    pipe_lassocv.fit(Xapp, yapp)\n    pipe_ridgecv.fit(Xapp, yapp)\n    # prediction\n    RES.loc[val_index,\"Logistic_brut\"] = pipe_logistic.predict(Xval).ravel()\n    RES.loc[val_index,\"Lasso_brut\"] = pipe_lassocv.predict(Xval).ravel()\n    RES.loc[val_index,\"Ridge_brut\"] = pipe_ridgecv.predict(Xval).ravel()\n```\n:::\n\n\n::: {#786a03cd .cell execution_count=33}\n``` {.python .cell-code}\nfor app_index, val_index in skf.split(X,y):\n    Xapp = X.iloc[app_index,:-1]\n    yapp = y.iloc[app_index]\n    Xval = X.iloc[val_index,:-1]\n    ## RandomOverSampler\n    ros1 = RandomOverSampler(random_state=123)\n    Xreech, yreech = ros1.fit_resample(Xapp, yapp)\n    # grille\n    Cs_lasso = grille(Xreech, yreech, \"lasso\")\n    Cs_ridge = grille(Xreech, yreech, \"ridge\")\n    # instanciation\n    cr = StandardScaler()\n    logistic =  LogisticRegression(penalty=None, solver=\"newton-cholesky\")\n    lassocv =  LogisticRegressionCV(cv=10, penalty=\"l1\", n_jobs=10, Cs=Cs_lasso,  solver=\"saga\", max_iter=2000)\n    ridgecv = LogisticRegressionCV(cv=10, penalty=\"l2\", n_jobs=10, Cs=Cs_ridge,  max_iter=1000)\n    pipe_logistic = Pipeline(steps=[(\"cr\", cr), (\"logistic\", logistic)])\n    pipe_lassocv = Pipeline(steps=[(\"cr\", cr), (\"lassocv\", lassocv)])\n    pipe_ridgecv = Pipeline(steps=[(\"cr\", cr), (\"ridgecv\", ridgecv)])\n    # fit\n    pipe_logistic.fit(Xreech, yreech)\n    pipe_lassocv.fit(Xapp, yapp)\n    pipe_ridgecv.fit(Xreech, yreech)\n    # prediction\n    RES.loc[val_index,\"Logistic_ros\"] = pipe_logistic.predict(Xval).ravel()\n    RES.loc[val_index,\"Lasso_ros\"] = pipe_lassocv.predict(Xval).ravel()\n    RES.loc[val_index,\"Ridge_ros\"] = pipe_ridgecv.predict(Xval).ravel()\n    ## Smote\n    sm = RandomOverSampler(random_state=123)\n    Xreech, yreech = sm.fit_resample(Xapp, yapp)\n    # grille\n    Cs_lasso = grille(Xreech, yreech, \"lasso\")\n    Cs_ridge = grille(Xreech, yreech, \"ridge\")\n    # instanciation\n    cr = StandardScaler()\n    logistic =  LogisticRegression(penalty=None, solver=\"newton-cholesky\")\n    lassocv =  LogisticRegressionCV(cv=10, penalty=\"l1\", n_jobs=10, Cs=Cs_lasso,  solver=\"saga\", max_iter=2000)\n    ridgecv = LogisticRegressionCV(cv=10, penalty=\"l2\", n_jobs=10, Cs=Cs_ridge,  max_iter=1000)\n    pipe_logistic = Pipeline(steps=[(\"cr\", cr), (\"logistic\", logistic)])\n    pipe_lassocv = Pipeline(steps=[(\"cr\", cr), (\"lassocv\", lassocv)])\n    pipe_ridgecv = Pipeline(steps=[(\"cr\", cr), (\"ridgecv\", ridgecv)])\n    # fit\n    pipe_logistic.fit(Xreech, yreech)\n    pipe_lassocv.fit(Xapp, yapp)\n    pipe_ridgecv.fit(Xreech, yreech)\n    # prediction\n    RES.loc[val_index,\"Logistic_smote\"] = pipe_logistic.predict(Xval).ravel()\n    RES.loc[val_index,\"Lasso_smote\"] = pipe_lassocv.predict(Xval).ravel()\n    RES.loc[val_index,\"Ridge_smote\"] = pipe_ridgecv.predict(Xval).ravel()\n```\n:::\n\n\n::: {#c136a11f .cell execution_count=34}\n``` {.python .cell-code}\nfor app_index, val_index in skf.split(X,y):\n    Xapp = X.iloc[app_index,:-1]\n    yapp = y.iloc[app_index]\n    Xval = X.iloc[val_index,:-1]\n    ## RandomUnderSampler\n    rus1 = RandomUnderSampler(random_state=123)\n    Xreech, yreech = rus1.fit_resample(Xapp, yapp)\n    # grille\n    Cs_lasso = grille(Xreech, yreech, \"lasso\")\n    Cs_ridge = grille(Xreech, yreech, \"ridge\")\n    # instanciation\n    cr = StandardScaler()\n    logistic =  LogisticRegression(penalty=None,solver=\"newton-cholesky\" )\n    lassocv =  LogisticRegressionCV(cv=10, penalty=\"l1\", n_jobs=10, Cs=Cs_lasso,  solver=\"saga\", max_iter=2000)\n    ridgecv = LogisticRegressionCV(cv=10, penalty=\"l2\", n_jobs=10, Cs=Cs_ridge,  max_iter=1000)\n    pipe_logistic = Pipeline(steps=[(\"cr\", cr), (\"logistic\", logistic)])\n    pipe_lassocv = Pipeline(steps=[(\"cr\", cr), (\"lassocv\", lassocv)])\n    pipe_ridgecv = Pipeline(steps=[(\"cr\", cr), (\"ridgecv\", ridgecv)])\n    # fit\n    pipe_logistic.fit(Xreech, yreech)\n    pipe_lassocv.fit(Xapp, yapp)\n    pipe_ridgecv.fit(Xreech, yreech)\n    # prediction\n    RES.loc[val_index,\"Logistic_rus\"] = pipe_logistic.predict(Xval).ravel()\n    RES.loc[val_index,\"Lasso_rus\"] = pipe_lassocv.predict(Xval).ravel()\n    RES.loc[val_index,\"Ridge_rus\"] = pipe_ridgecv.predict(Xval).ravel()\n    ## Tomek\n    tl = TomekLinks(sampling_strategy='all')\n    Xreech, yreech = tl.fit_resample(Xapp, yapp)\n    # grille\n    Cs_lasso = grille(Xreech, yreech, \"lasso\")\n    Cs_ridge = grille(Xreech, yreech, \"ridge\")\n    # instanciation\n    cr = StandardScaler()\n    logistic =  LogisticRegression(penalty=None, solver=\"newton-cholesky\")\n    lassocv =  LogisticRegressionCV(cv=10, penalty=\"l1\", n_jobs=10, Cs=Cs_lasso,  solver=\"saga\", max_iter=2000)\n    ridgecv = LogisticRegressionCV(cv=10, penalty=\"l2\", n_jobs=10, Cs=Cs_ridge,  max_iter=1000)\n    pipe_logistic = Pipeline(steps=[(\"cr\", cr), (\"logistic\", logistic)])\n    pipe_lassocv = Pipeline(steps=[(\"cr\", cr), (\"lassocv\", lassocv)])\n    pipe_ridgecv = Pipeline(steps=[(\"cr\", cr), (\"ridgecv\", ridgecv)])\n    # fit\n    pipe_logistic.fit(Xreech, yreech)\n    pipe_lassocv.fit(Xapp, yapp)\n    pipe_ridgecv.fit(Xreech, yreech)\n    # prediction\n    RES.loc[val_index,\"Logistic_tomek\"] = pipe_logistic.predict(Xval).ravel()\n    RES.loc[val_index,\"Lasso_tomek\"] = pipe_lassocv.predict(Xval).ravel()\n    RES.loc[val_index,\"Ridge_tomek\"] = pipe_ridgecv.predict(Xval).ravel()\n```\n:::\n\n\n\n\n::: {#95caddd1 .cell execution_count=36}\n``` {.python .cell-code}\nauc = pd.Series(0.0, index=RES.columns[1:])\nfor i in range(auc.shape[0]):\n    auc.iloc[i] = sklm.roc_auc_score(RES.Y, RES.iloc[:,i+1])\n\nround(auc,3)\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```\nLogistic_brut     0.914\nLogistic_ros      0.905\nLogistic_smote    0.905\nLogistic_rus      0.890\nLogistic_tomek    0.917\nLasso_brut        0.907\nLasso_ros         0.687\nLasso_smote       0.687\nLasso_rus         0.690\nLasso_tomek       0.908\nRidge_brut        0.912\nRidge_ros         0.924\nRidge_smote       0.924\nRidge_rus         0.919\nRidge_tomek       0.911\ndtype: float64\n```\n:::\n:::\n\n\n::: {#8fc7568c .cell execution_count=37}\n``` {.python .cell-code}\nacc = pd.Series(0.0, index=RES.columns[1:])\ns = 0.5\nfor i in range(acc.shape[0]):\n    acc.iloc[i] = 1-sklm.zero_one_loss(RES.Y, RES.iloc[:,i+1]>s)\n\nround(acc,3)\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```\nLogistic_brut     0.956\nLogistic_ros      0.949\nLogistic_smote    0.949\nLogistic_rus      0.892\nLogistic_tomek    0.958\nLasso_brut        0.970\nLasso_ros         0.912\nLasso_smote       0.912\nLasso_rus         0.912\nLasso_tomek       0.970\nRidge_brut        0.971\nRidge_ros         0.958\nRidge_smote       0.958\nRidge_rus         0.947\nRidge_tomek       0.970\ndtype: float64\n```\n:::\n:::\n\n\n::: {#f9b3ea0b .cell execution_count=38}\n``` {.python .cell-code}\nbal = pd.Series(0.0, index=RES.columns[1:])\ns = 0.5\nfor i in range(bal.shape[0]):\n    bal.iloc[i] = sklm.balanced_accuracy_score(RES.Y, RES.iloc[:,i+1]>s)\n\nround(bal,3)\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\nLogistic_brut     0.914\nLogistic_ros      0.905\nLogistic_smote    0.905\nLogistic_rus      0.890\nLogistic_tomek    0.917\nLasso_brut        0.907\nLasso_ros         0.687\nLasso_smote       0.687\nLasso_rus         0.690\nLasso_tomek       0.908\nRidge_brut        0.912\nRidge_ros         0.924\nRidge_smote       0.924\nRidge_rus         0.919\nRidge_tomek       0.911\ndtype: float64\n```\n:::\n:::\n\n\n::: {#7c99d783 .cell execution_count=39}\n``` {.python .cell-code}\nf1s = pd.Series(0.0, index=RES.columns[1:])\ns = 0.5\nfor i in range(f1s.shape[0]):\n    f1s.iloc[i] = sklm.f1_score(RES.Y, RES.iloc[:,i+1]>s)\n\nround(f1s,3)\n```\n\n::: {.cell-output .cell-output-display execution_count=33}\n```\nLogistic_brut     0.845\nLogistic_ros      0.822\nLogistic_smote    0.822\nLogistic_rus      0.697\nLogistic_tomek    0.852\nLasso_brut        0.883\nLasso_ros         0.543\nLasso_smote       0.543\nLasso_rus         0.549\nLasso_tomek       0.885\nRidge_brut        0.889\nRidge_ros         0.854\nRidge_smote       0.854\nRidge_rus         0.822\nRidge_tomek       0.887\ndtype: float64\n```\n:::\n:::\n\n\n::: {#21efa205 .cell execution_count=40}\n``` {.python .cell-code}\nkappa_scores = pd.Series(0.0, index=RES.columns[1:])\ns = 0.5\nfor i in range(kappa_scores.shape[0]):\n    kappa_scores.iloc[i] = sklm.cohen_kappa_score(RES.Y, RES.iloc[:,i+1] > s)\n\nround(kappa_scores, 3)\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```\nLogistic_brut     0.820\nLogistic_ros      0.792\nLogistic_smote    0.792\nLogistic_rus      0.635\nLogistic_tomek    0.828\nLasso_brut        0.865\nLasso_ros         0.504\nLasso_smote       0.504\nLasso_rus         0.510\nLasso_tomek       0.868\nRidge_brut        0.873\nRidge_ros         0.829\nRidge_smote       0.829\nRidge_rus         0.791\nRidge_tomek       0.870\ndtype: float64\n```\n:::\n:::\n\n\n",
    "supporting": [
      "chap16_files"
    ],
    "filters": [],
    "includes": {}
  }
}