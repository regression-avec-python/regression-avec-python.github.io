{
  "hash": "2ef7ba0f83b0cc2a92e4c5d5600505b5",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"11 Comparaison des différentes méthodes, étude de cas réels\"\ntoc: true\n---\n\n::: {#a2f3dcea .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd; import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LinearRegression, Ridge, \\\nElasticNet, Lasso\nfrom sklearn.linear_model import RidgeCV, ElasticNetCV, LassoCV\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV, KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom patsy import dmatrix\n\nimport sys\nsys.path.append('../modules')\nimport ols_step_sk\n```\n:::\n\n\n#   Erreur de prévision et validation croisée\n\n#   Analyse de l'ozone\n\n::: {#4a8cb433 .cell execution_count=2}\n``` {.python .cell-code}\nozone = pd.read_csv(\"../donnees/ozone_complet.txt\", header = 0, sep = \";\", index_col=0)\nozone.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n(1464, 23)\n```\n:::\n:::\n\n\n::: {#627cec89 .cell execution_count=3}\n``` {.python .cell-code}\nlesna = pd.isna(ozone)\nindNA = lesna.apply(any, axis=1)\nozone2 = ozone[~indNA]\nozone2.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n(1366, 23)\n```\n:::\n:::\n\n\n::: {#57c6d4b1 .cell execution_count=4}\n``` {.python .cell-code}\ndon = pd.read_csv(\"../donnees/ozone_transf.txt\", header = 0, sep = \";\", index_col=0)\ndon.shape\ndon.rename(columns={\"maxO3\":\"Y\"},inplace=True)\nY = don[\"Y\"].to_numpy()\n```\n:::\n\n\n::: {#d65b2e11 .cell execution_count=5}\n``` {.python .cell-code}\nnb=10\ntmp = np.arange(don.shape[0])%nb\n```\n:::\n\n\n::: {#b9ed2585 .cell execution_count=6}\n``` {.python .cell-code}\nrng = np.random.default_rng(seed=1234)\nbloc = rng.choice(tmp,size=don.shape[0],replace=False)\n```\n:::\n\n\n::: {#3484f1a0 .cell execution_count=7}\n``` {.python .cell-code}\nPREV = pd.DataFrame({\"bloc\":bloc,\"Y\":don[\"Y\"],\"MCO\":0.0,\"BIC\":0.0,\"AIC\":0.0,\n                    \"ridge\":0.0,\"lasso\":0.0,\"elast\":0.0,\n                    \"pls\":0.0,\"pcr\":0.0})\n```\n:::\n\n\n::: {#902502fc .cell execution_count=8}\n``` {.python .cell-code}\nnomsvar = list(don.columns.difference([\"Y\"]))\n#design matrix\nformule = \"~\" + \"+\".join(nomsvar)\ndsX = dmatrix(formule,don)\nX = np.asarray(dsX)[:,1:]\nY = don[\"Y\"].to_numpy()\n```\n:::\n\n\n::: {#b201e188 .cell execution_count=9}\n``` {.python .cell-code}\nkfregul = KFold(n_splits=10, shuffle=True, random_state=0)\nkfaxes = KFold(n_splits=4, shuffle=True, random_state=0)\nnbaxes = 20\n# instanciation steps\ncr = StandardScaler()\nlassocv = LassoCV(cv=kfregul, n_jobs=3,max_iter=1000)\nenetcv = ElasticNetCV(cv=kfregul, n_jobs=3,max_iter=1000)\n# instanciation pipeline\npipe_lassocv = Pipeline(steps=[(\"cr\", cr), (\"lassocv\", lassocv)])\npipe_enetcv = Pipeline(steps=[(\"cr\", cr), (\"enetcv\", enetcv)])\n## ridge : path\netape_lasso = pipe_lassocv.named_steps[\"lassocv\"]\n# intanciations\nridge = Ridge()\npipe_ridge = Pipeline(steps=[(\"cr\", cr), (\"ridge\", ridge)])\nacp = PCA()\nreg = LinearRegression()\npipe_pcr = Pipeline(steps=[(\"cr\", cr), (\"acp\", acp), (\"reg\", reg)])\nregpls = PLSRegression()\n## grille composantes et decoupage VC\nparam_grid_pcr = { \"acp__n_components\" : list(range(1,nbaxes))}\nparam_grid_pls = { \"n_components\" : list(range(1,nbaxes))}\n```\n:::\n\n\n::: {#comparaison_simple .cell cache='true' execution_count=10}\n``` {.python .cell-code}\nfor i in np.arange(nb):\n    print(i)\n    Xapp = X[bloc!=i,:]\n    Xtest = X[bloc==i,:]\n    Yapp = don[bloc!=i][\"Y\"]\n    Ytest = don[bloc==i][\"Y\"]\n    #### reg\n    reg = LinearRegression()\n    reg.fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"MCO\"] = reg.predict(Xtest)\n    ### bic\n    inst_reg_bic = ols_step_sk.LinearRegressionSelectionFeatureIC(verbose=1,crit=\"bic\")\n    reg_bic = inst_reg_bic.fit(X=Xapp, y=Yapp)\n    PREV.loc[PREV.bloc==i,\"BIC\"] = reg_bic.predict(Xtest)\n    ### aic\n    inst_reg_aic = ols_step_sk.LinearRegressionSelectionFeatureIC(verbose=1,crit=\"aic\")\n    reg_aic = inst_reg_aic.fit(X=Xapp, y=Yapp)\n    PREV.loc[PREV.bloc==i,\"AIC\"] = reg_aic.predict(Xtest)\n    ## lasso\n    pipe_lassocv.fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"lasso\"] = pipe_lassocv.predict(Xtest)\n    ## elastic net\n    pipe_enetcv.fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"elast\"] = pipe_enetcv.predict(Xtest)    \n    ## params lambda\n    path_ridge = etape_lasso.alphas_ * 100    \n    param_grid_ridge = {\"ridge__alpha\": path_ridge}\n    ## GridSearchCV\n    cv_ridge = GridSearchCV(pipe_ridge, param_grid_ridge, cv=kfregul, scoring = \"neg_mean_squared_error\", n_jobs=3).fit(Xapp, Yapp)\n    PREV.loc[PREV.bloc==i,\"ridge\"] = cv_ridge.predict(Xtest)\n    ## gridsearch instanciation et fit\n    cv_pcr = GridSearchCV(pipe_pcr, param_grid_pcr, cv=kfaxes, scoring = \"neg_mean_squared_error\", n_jobs=3).fit(Xapp,Yapp)\n    cv_pls = GridSearchCV(regpls, param_grid_pls, cv=kfaxes, scoring = \"neg_mean_squared_error\", n_jobs=3).fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"pcr\"] = cv_pcr.predict(Xtest)\n    PREV.loc[PREV.bloc==i,\"pls\"] = cv_pls.predict(Xtest)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0\nFinal: [0, 4, 5, 8, 11, 20]\nFinal: [0, 4, 5, 6, 8, 11, 18, 19, 20]\n1\nFinal: [0, 4, 5, 8, 10, 20]\nFinal: [0, 4, 5, 6, 8, 10, 11, 12, 19, 20]\n2\nFinal: [0, 5, 8, 11, 20]\nFinal: [0, 4, 5, 6, 8, 11, 12, 13, 20]\n3\nFinal: [0, 4, 5, 8, 11, 20]\nFinal: [0, 4, 5, 6, 8, 11, 12, 18, 19, 20]\n4\nFinal: [0, 5, 8, 10, 20]\nFinal: [0, 4, 5, 6, 8, 10, 20]\n5\nFinal: [0, 5, 8, 10, 20]\nFinal: [0, 4, 5, 6, 8, 10, 18, 19, 20]\n6\nFinal: [0, 5, 8, 10, 20]\nFinal: [0, 1, 4, 5, 8, 10, 11, 12, 15, 19, 20]\n7\nFinal: [0, 5, 8, 10, 20]\nFinal: [0, 1, 4, 5, 8, 10, 11, 12, 15, 19, 20]\n8\nFinal: [0, 5, 8, 10, 20]\nFinal: [0, 1, 4, 5, 8, 10, 19, 20]\n9\nFinal: [0, 5, 8, 11, 20]\nFinal: [0, 4, 5, 6, 8, 11, 12, 18, 19, 20]\n```\n:::\n:::\n\n\n::: {#ba06242e .cell execution_count=11}\n``` {.python .cell-code}\nprev = PREV.iloc[:,1:]\nnp.round((prev.sub(PREV.Y, axis=0)**2).mean(),2)\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\nY          0.00\nMCO      187.51\nBIC      188.23\nAIC      187.74\nridge    187.43\nlasso    187.05\nelast    187.20\npls      187.92\npcr      188.22\ndtype: float64\n```\n:::\n:::\n\n\n#   Transformation des variables : feature engineering\n\n##  Modèles de prévision avec interactions\n\n::: {#910e5c90 .cell execution_count=12}\n``` {.python .cell-code}\nformuleI = \"1 + (\" + \"+\".join(nomsvar) + \")**2\"\nXinter = dmatrix(formuleI, don, return_type=\"dataframe\").\\\n    iloc[:,1:].to_numpy()\n```\n:::\n\n\n::: {#f2eb2f38 .cell execution_count=13}\n``` {.python .cell-code}\nformuleI = \"1 + (\" + \"+\".join(nomsvar) + \")**2\"\nXq = dmatrix(formuleI, don)\nXinter = np.asarray(Xq)[:,1:]\nXinter.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\n(1366, 231)\n```\n:::\n:::\n\n\n::: {#comparaison_inter .cell cache='true' execution_count=14}\n``` {.python .cell-code}\nkfregul = KFold(n_splits=10, shuffle=True, random_state=0)\nkfaxes = KFold(n_splits=4, shuffle=True, random_state=0)\nnbaxes = 40\n# instanciation steps\ncr = StandardScaler()\nlassocv = LassoCV(cv=kfregul, n_jobs=3,max_iter=5000)\nenetcv = ElasticNetCV(cv=kfregul, n_jobs=3,max_iter=5000)\n# instanciation pipeline\npipe_lassocv = Pipeline(steps=[(\"cr\", cr), (\"lassocv\", lassocv)])\npipe_enetcv = Pipeline(steps=[(\"cr\", cr), (\"enetcv\", enetcv)])\n## ridge : path\netape_lasso = pipe_lassocv.named_steps[\"lassocv\"]\n# intanciations\nridge = Ridge()\npipe_ridge = Pipeline(steps=[(\"cr\", cr), (\"ridge\", ridge)])\nacp = PCA()\nreg = LinearRegression()\npipe_pcr = Pipeline(steps=[(\"cr\", cr), (\"acp\", acp), (\"reg\", reg)])\nregpls = PLSRegression()\n## grille composantes et decoupage VC\nparam_grid_pcr = { \"acp__n_components\" : list(range(1,nbaxes))}\nparam_grid_pls = { \"n_components\" : list(range(1,nbaxes))}\n \nfor i in np.arange(nb):\n    print(i)\n    Xapp = Xinter[bloc!=i,:]\n    Xtest = Xinter[bloc==i,:]\n    Yapp = don[bloc!=i][\"Y\"]\n    Ytest = don[bloc==i][\"Y\"]\n    #### reg\n    reg = LinearRegression()\n    reg.fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"MCO\"] = reg.predict(Xtest)\n    ### bic\n    inst_reg_bic = ols_step_sk.LinearRegressionSelectionFeatureIC(verbose=1,crit=\"bic\")\n    reg_bic = inst_reg_bic.fit(X=Xapp, y=Yapp)\n    PREV.loc[PREV.bloc==i,\"BIC\"] = reg_bic.predict(Xtest)\n    ### aic\n    inst_reg_aic = ols_step_sk.LinearRegressionSelectionFeatureIC(verbose=1,crit=\"aic\")\n    reg_aic = inst_reg_aic.fit(X=Xapp, y=Yapp)\n    PREV.loc[PREV.bloc==i,\"AIC\"] = reg_aic.predict(Xtest)\n    ## lasso\n    pipe_lassocv.fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"lasso\"] = pipe_lassocv.predict(Xtest)\n    ## elastic net\n    pipe_enetcv.fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"elast\"] = pipe_enetcv.predict(Xtest)    \n    ## params lambda\n    path_ridge = etape_lasso.alphas_ * 100    \n    param_grid_ridge = {\"ridge__alpha\": path_ridge}\n    ## GridSearchCV\n    cv_ridge = GridSearchCV(pipe_ridge, param_grid_ridge, cv=kfregul, scoring = \"neg_mean_squared_error\", n_jobs=3).fit(Xapp, Yapp)\n    PREV.loc[PREV.bloc==i,\"ridge\"] = cv_ridge.predict(Xtest)\n    ## gridsearch instanciation et fit\n    cv_pcr = GridSearchCV(pipe_pcr, param_grid_pcr, cv=kfaxes, scoring = \"neg_mean_squared_error\", n_jobs=3).fit(Xapp,Yapp)\n    cv_pls = GridSearchCV(regpls, param_grid_pls, cv=kfaxes, scoring = \"neg_mean_squared_error\", n_jobs=3).fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"pcr\"] = cv_pcr.predict(Xtest)\n    PREV.loc[PREV.bloc==i,\"pls\"] = cv_pls.predict(Xtest)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0\nFinal: [5, 20, 21, 47, 98, 111, 125, 139, 142, 164, 185, 228]\nFinal: [1, 4, 5, 8, 13, 20, 21, 38, 41, 49, 62, 64, 82, 90, 98, 108, 110, 111, 115, 125, 127, 137, 139, 142, 143, 150, 152, 164, 165, 168, 192, 206, 221, 229]\n1\nFinal: [1, 5, 8, 20, 21, 98, 111, 125, 139, 142, 164, 185, 193]\nFinal: [1, 5, 7, 8, 9, 13, 20, 21, 22, 29, 38, 40, 41, 44, 46, 49, 73, 77, 98, 101, 108, 111, 114, 115, 125, 127, 137, 142, 143, 145, 150, 164, 165, 167, 183, 185, 193, 202, 206, 229]\n2\nFinal: [6, 10, 21, 40, 59, 95, 111, 139, 142, 153]\nFinal: [2, 4, 6, 8, 10, 11, 13, 20, 21, 38, 41, 42, 59, 62, 64, 75, 85, 90, 91, 98, 100, 109, 110, 111, 116, 118, 123, 126, 128, 137, 139, 140, 144, 149, 150, 153, 164, 166, 172, 183, 185, 194, 202, 205, 209, 221, 229]\n3\nFinal: [6, 9, 14, 20, 22, 53, 97, 111, 119, 164, 192]\nFinal: [6, 7, 8, 9, 13, 14, 20, 21, 41, 47, 53, 59, 61, 63, 64, 66, 85, 98, 101, 104, 111, 112, 119, 130, 137, 139, 143, 150, 158, 164, 168, 176, 192, 195, 221, 229, 230]\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n4\nFinal: [7, 10, 20, 27, 41, 59, 77, 115, 125, 126, 164]\nFinal: [2, 4, 7, 13, 20, 24, 37, 41, 42, 43, 49, 59, 85, 90, 97, 101, 110, 115, 125, 126, 132, 137, 139, 142, 150, 154, 164, 183, 185, 190, 191, 193, 206, 209, 221, 229]\n5\nFinal: [6, 10, 20, 21, 59, 111, 113, 115]\nFinal: [4, 6, 8, 10, 11, 13, 20, 21, 22, 24, 41, 57, 59, 90, 97, 110, 111, 113, 115, 126, 128, 137, 142, 145, 150, 162, 164, 165, 183, 185, 194, 203, 209, 211, 221, 229]\n6\nFinal: [4, 6, 20, 24, 28, 41, 77, 97, 115, 125, 126, 164, 185, 192, 205]\nFinal: [4, 6, 13, 20, 21, 24, 28, 41, 49, 59, 77, 90, 97, 110, 111, 115, 117, 118, 125, 126, 128, 137, 144, 150, 164, 167, 183, 185, 190, 191, 194, 206, 209, 221, 226]\n7\nFinal: [5, 20, 21, 111, 125, 139, 142, 164, 185]\nFinal: [1, 4, 5, 8, 13, 20, 21, 41, 49, 77, 80, 90, 98, 101, 110, 111, 115, 116, 117, 125, 127, 130, 131, 137, 139, 149, 150, 154, 155, 156, 157, 161, 164, 167, 168, 185, 192, 201, 202, 221, 223, 227]\n8\nFinal: [4, 7, 10, 20, 21, 59, 96, 115, 125, 126, 164]\nFinal: [4, 5, 11, 13, 20, 21, 24, 29, 38, 41, 51, 59, 90, 96, 97, 110, 111, 115, 117, 125, 128, 130, 137, 139, 142, 150, 152, 157, 162, 164, 167, 168, 221, 226, 229]\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n9\nFinal: [1, 5, 10, 20, 21, 111, 115, 125, 139, 164, 191, 206]\nFinal: [1, 2, 4, 5, 7, 13, 20, 21, 24, 37, 38, 41, 47, 62, 64, 73, 79, 81, 91, 95, 97, 110, 111, 115, 117, 122, 125, 127, 130, 131, 137, 139, 142, 145, 150, 166, 172, 192, 205, 229]\n```\n:::\n:::\n\n\n::: {#fc517ddc .cell execution_count=15}\n``` {.python .cell-code}\nprev = PREV.iloc[:,1:]\nround((prev.sub(PREV.Y, axis=0)**2).mean(),2)\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\nY          0.00\nMCO      187.73\nBIC      168.28\nAIC      168.38\nridge    165.13\nlasso    161.60\nelast    164.25\npls      168.91\npcr      173.75\ndtype: float64\n```\n:::\n:::\n\n\n##  Modèles de prévision avec des polynômes\n\n::: {#3d12ac39 .cell execution_count=16}\n``` {.python .cell-code}\nXcar = X**2\nXcub = X**3\nXpol = np.concatenate((X, Xcar, Xcub), axis=1)\nXpol.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n(1366, 63)\n```\n:::\n:::\n\n\n::: {#comparaison_poly .cell cache='true' execution_count=17}\n``` {.python .cell-code}\nkfregul = KFold(n_splits=10, shuffle=True, random_state=0)\nkfaxes = KFold(n_splits=4, shuffle=True, random_state=0)\nnbaxes = 40\n# instanciation steps\ncr = StandardScaler()\nlassocv = LassoCV(cv=kfregul, n_jobs=3,max_iter=3000)\nenetcv = ElasticNetCV(cv=kfregul, n_jobs=3,max_iter=3000)\n# instanciation pipeline\npipe_lassocv = Pipeline(steps=[(\"cr\", cr), (\"lassocv\", lassocv)])\npipe_enetcv = Pipeline(steps=[(\"cr\", cr), (\"enetcv\", enetcv)])\n## ridge : path\netape_lasso = pipe_lassocv.named_steps[\"lassocv\"]\n# intanciations\nridge = Ridge()\npipe_ridge = Pipeline(steps=[(\"cr\", cr), (\"ridge\", ridge)])\nacp = PCA()\nreg = LinearRegression()\npipe_pcr = Pipeline(steps=[(\"cr\", cr), (\"acp\", acp), (\"reg\", reg)])\nregpls = PLSRegression()\n## grille composantes et decoupage VC\nparam_grid_pcr = { \"acp__n_components\" : list(range(1,nbaxes))}\nparam_grid_pls = { \"n_components\" : list(range(1,nbaxes))}\n \nfor i in np.arange(nb):\n    print(i)\n    Xapp = Xpol[bloc!=i,:]\n    Xtest = Xpol[bloc==i,:]\n    Yapp = don[bloc!=i][\"Y\"]\n    Ytest = don[bloc==i][\"Y\"]\n    #### reg\n    reg = LinearRegression()\n    reg.fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"MCO\"] = reg.predict(Xtest)\n    ### bic\n    inst_reg_bic = ols_step_sk.LinearRegressionSelectionFeatureIC(verbose=1,crit=\"bic\")\n    reg_bic = inst_reg_bic.fit(X=Xapp, y=Yapp)\n    PREV.loc[PREV.bloc==i,\"BIC\"] = reg_bic.predict(Xtest)\n    ### aic\n    inst_reg_aic = ols_step_sk.LinearRegressionSelectionFeatureIC(verbose=1,crit=\"aic\")\n    reg_aic = inst_reg_aic.fit(X=Xapp, y=Yapp)\n    PREV.loc[PREV.bloc==i,\"AIC\"] = reg_aic.predict(Xtest)\n    ## lasso\n    pipe_lassocv.fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"lasso\"] = pipe_lassocv.predict(Xtest)\n    ## elastic net\n    pipe_enetcv.fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"elast\"] = pipe_enetcv.predict(Xtest)    \n    ## params lambda\n    path_ridge = etape_lasso.alphas_ * 100    \n    param_grid_ridge = {\"ridge__alpha\": path_ridge}\n    ## GridSearchCV\n    cv_ridge = GridSearchCV(pipe_ridge, param_grid_ridge, cv=kfregul, scoring = \"neg_mean_squared_error\", n_jobs=3).fit(Xapp, Yapp)\n    PREV.loc[PREV.bloc==i,\"ridge\"] = cv_ridge.predict(Xtest)\n    ## gridsearch instanciation et fit\n    cv_pcr = GridSearchCV(pipe_pcr, param_grid_pcr, cv=kfaxes, scoring = \"neg_mean_squared_error\", n_jobs=3).fit(Xapp,Yapp)\n    cv_pls = GridSearchCV(regpls, param_grid_pls, cv=kfaxes, scoring = \"neg_mean_squared_error\", n_jobs=3).fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"pcr\"] = cv_pcr.predict(Xtest)\n    PREV.loc[PREV.bloc==i,\"pls\"] = cv_pls.predict(Xtest)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0\nFinal: [11, 20, 21, 26, 29, 43, 47]\nFinal: [0, 1, 4, 11, 19, 20, 21, 26, 27, 29, 31, 34, 35, 38, 42, 43, 47, 52, 53, 56]\n1\nFinal: [11, 20, 21, 26, 29, 43, 47, 53]\nFinal: [0, 1, 4, 8, 11, 12, 13, 19, 20, 21, 22, 26, 29, 31, 34, 35, 38, 42, 47, 48, 52, 53, 56]\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n2\nFinal: [5, 11, 20, 29, 38, 42, 47, 48]\nFinal: [0, 1, 4, 5, 8, 11, 13, 19, 20, 21, 22, 29, 31, 34, 35, 38, 42, 47, 48, 52, 53, 56]\n3\nFinal: [5, 11, 20, 21, 29, 33, 38, 47, 48, 53]\nFinal: [1, 5, 10, 11, 12, 19, 20, 21, 29, 31, 33, 34, 35, 38, 43, 46, 47, 48, 53, 54, 56]\n4\nFinal: [11, 20, 21, 26, 29, 43, 47]\nFinal: [0, 1, 4, 8, 10, 11, 18, 19, 20, 21, 26, 27, 29, 31, 34, 35, 38, 42, 43, 47, 56, 60]\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n5\nFinal: [5, 11, 20, 29, 38, 42, 47, 48, 53]\nFinal: [0, 1, 4, 5, 8, 10, 11, 19, 20, 21, 22, 29, 34, 35, 38, 41, 42, 47, 48, 53, 56, 62]\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n6\nFinal: [5, 11, 20, 21, 29, 43, 47]\nFinal: [0, 5, 8, 11, 12, 19, 20, 21, 27, 29, 31, 34, 35, 38, 42, 43, 46, 47, 52, 53, 56]\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n7\nFinal: [11, 20, 21, 26, 29, 43, 47]\nFinal: [1, 11, 12, 19, 20, 21, 26, 27, 29, 31, 34, 35, 38, 43, 46, 47, 52, 53, 56]\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n8\nFinal: [5, 11, 20, 21, 29, 43, 47]\nFinal: [0, 1, 5, 11, 19, 20, 21, 22, 29, 33, 34, 35, 38, 42, 46, 47, 48, 52, 53, 56]\n9\nFinal: [0, 1, 5, 11, 16, 20, 29, 38, 43, 47, 53]\nFinal: [0, 1, 5, 8, 10, 11, 19, 20, 21, 22, 29, 31, 34, 35, 38, 42, 46, 47, 48, 53, 56]\n```\n:::\n:::\n\n\n::: {#2243c4f6 .cell execution_count=18}\n``` {.python .cell-code}\nprev = PREV.iloc[:,1:]\nround((prev.sub(PREV.Y, axis=0)**2).mean(),2)\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\nY          0.00\nMCO      165.40\nBIC      167.61\nAIC      164.87\nridge    165.08\nlasso    163.90\nelast    164.76\npls      166.16\npcr      169.63\ndtype: float64\n```\n:::\n:::\n\n\n##  Modèles de prévision des splines\n\n::: {#36f1ac5d .cell execution_count=19}\n``` {.python .cell-code}\nXp = np.ones((X.shape[0],1))\nfor i in nomsvar:\n    xi = don.loc[:,i].quantile([0.25, 0.5, 0.75])\n    formule = \"-1 + bs(\" + i + \",knots=xi, degree=3)\"\n    BX = dmatrix(formule, don)\n    Xp = np.concatenate((Xp, BX), axis=1)\n\nXspline = Xp[:,1:]\n```\n:::\n\n\n::: {#comparaison_spline .cell cache='true' execution_count=20}\n``` {.python .cell-code}\nkfregul = KFold(n_splits=10, shuffle=True, random_state=0)\nkfaxes = KFold(n_splits=4, shuffle=True, random_state=0)\nnbaxes = 40\n# instanciation steps\ncr = StandardScaler()\nlassocv = LassoCV(cv=kfregul, n_jobs=3,max_iter=3000)\nenetcv = ElasticNetCV(cv=kfregul, n_jobs=3,max_iter=3000)\n# instanciation pipeline\npipe_lassocv = Pipeline(steps=[(\"cr\", cr), (\"lassocv\", lassocv)])\npipe_enetcv = Pipeline(steps=[(\"cr\", cr), (\"enetcv\", enetcv)])\n## ridge : path\netape_lasso = pipe_lassocv.named_steps[\"lassocv\"]\n# intanciations\nridge = Ridge()\npipe_ridge = Pipeline(steps=[(\"cr\", cr), (\"ridge\", ridge)])\nacp = PCA()\nreg = LinearRegression()\npipe_pcr = Pipeline(steps=[(\"cr\", cr), (\"acp\", acp), (\"reg\", reg)])\nregpls = PLSRegression()\n## grille composantes et decoupage VC\nparam_grid_pcr = { \"acp__n_components\" : list(range(1,nbaxes))}\nparam_grid_pls = { \"n_components\" : list(range(1,nbaxes))}\n \nfor i in np.arange(nb):\n    print(i)\n    Xapp = Xspline[bloc!=i,:]\n    Xtest = Xspline[bloc==i,:]\n    Yapp = don[bloc!=i][\"Y\"]\n    Ytest = don[bloc==i][\"Y\"]\n    #### reg\n    reg = LinearRegression()\n    reg.fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"MCO\"] = reg.predict(Xtest)\n    ### bic\n    inst_reg_bic = ols_step_sk.LinearRegressionSelectionFeatureIC(verbose=1,crit=\"bic\")\n    reg_bic = inst_reg_bic.fit(X=Xapp, y=Yapp)\n    PREV.loc[PREV.bloc==i,\"BIC\"] = reg_bic.predict(Xtest)\n    ### aic\n    inst_reg_aic = ols_step_sk.LinearRegressionSelectionFeatureIC(verbose=1,crit=\"aic\")\n    reg_aic = inst_reg_aic.fit(X=Xapp, y=Yapp)\n    PREV.loc[PREV.bloc==i,\"AIC\"] = reg_aic.predict(Xtest)\n    ## lasso\n    pipe_lassocv.fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"lasso\"] = pipe_lassocv.predict(Xtest)\n    ## elastic net\n    pipe_enetcv.fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"elast\"] = pipe_enetcv.predict(Xtest)    \n    ## params lambda\n    path_ridge = etape_lasso.alphas_ * 100    \n    param_grid_ridge = {\"ridge__alpha\": path_ridge}\n    ## GridSearchCV\n    cv_ridge = GridSearchCV(pipe_ridge, param_grid_ridge, cv=kfregul, scoring = \"neg_mean_squared_error\", n_jobs=3).fit(Xapp, Yapp)\n    PREV.loc[PREV.bloc==i,\"ridge\"] = cv_ridge.predict(Xtest)\n    ## gridsearch instanciation et fit\n    cv_pcr = GridSearchCV(pipe_pcr, param_grid_pcr, cv=kfaxes, scoring = \"neg_mean_squared_error\", n_jobs=3).fit(Xapp,Yapp)\n    cv_pls = GridSearchCV(regpls, param_grid_pls, cv=kfaxes, scoring = \"neg_mean_squared_error\", n_jobs=3).fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"pcr\"] = cv_pcr.predict(Xtest)\n    PREV.loc[PREV.bloc==i,\"pls\"] = cv_pls.predict(Xtest)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0\nFinal: [3, 5, 29, 34, 35, 39, 51, 53, 67, 87, 120, 121, 124]\nFinal: [1, 3, 5, 7, 8, 23, 26, 28, 29, 34, 35, 39, 48, 51, 52, 53, 65, 67, 70, 73, 80, 87, 88, 92, 104, 107, 108, 120, 121, 123, 124, 125]\n1\nFinal: [3, 5, 34, 39, 41, 48, 51, 52, 87, 120, 121, 124]\nFinal: [0, 1, 3, 5, 7, 8, 23, 26, 28, 33, 34, 39, 40, 41, 46, 48, 49, 51, 52, 54, 59, 62, 65, 67, 70, 80, 82, 87, 88, 99, 102, 106, 120, 121, 123, 124, 125]\n2\nFinal: [1, 3, 5, 7, 34, 39, 41, 49, 52, 87, 120, 121, 124]\nFinal: [0, 1, 3, 5, 7, 12, 23, 26, 27, 28, 29, 33, 34, 39, 40, 41, 46, 49, 51, 52, 59, 65, 70, 82, 84, 87, 88, 92, 104, 107, 120, 121, 124]\n3\nFinal: [3, 5, 7, 28, 34, 41, 51, 52, 70, 77, 87, 88, 120, 121, 124]\nFinal: [0, 3, 5, 7, 8, 23, 26, 28, 31, 34, 38, 39, 40, 41, 44, 48, 49, 51, 52, 53, 56, 62, 67, 70, 73, 77, 80, 87, 88, 99, 103, 104, 122, 123, 124, 125]\n4\nFinal: [3, 5, 34, 39, 41, 51, 52, 87, 120, 121, 124]\nFinal: [0, 1, 3, 5, 7, 8, 23, 25, 26, 27, 28, 29, 33, 34, 35, 39, 40, 41, 45, 46, 49, 51, 52, 59, 65, 67, 70, 75, 80, 87, 88, 92, 102, 106, 120, 121, 123, 124]\n5\nFinal: [3, 5, 34, 39, 41, 48, 51, 52, 87, 104, 120, 121, 123, 124, 125]\nFinal: [0, 2, 4, 5, 7, 8, 23, 26, 28, 29, 34, 35, 39, 40, 41, 46, 48, 49, 51, 52, 59, 65, 67, 70, 73, 80, 87, 88, 92, 104, 122, 123, 124, 125]\n6\nFinal: [1, 3, 5, 7, 28, 34, 39, 40, 41, 49, 52, 87, 120, 121, 124]\nFinal: [0, 1, 3, 5, 7, 26, 28, 33, 34, 39, 40, 41, 46, 48, 49, 51, 52, 59, 65, 70, 80, 87, 88, 92, 104, 108, 109, 117, 122, 123, 124, 125]\n7\nFinal: [2, 7, 26, 28, 34, 39, 41, 49, 52, 65, 70, 87, 88, 120, 121, 124]\nFinal: [2, 7, 17, 23, 26, 27, 28, 29, 33, 34, 38, 39, 40, 41, 43, 46, 48, 49, 51, 52, 53, 65, 67, 70, 73, 80, 85, 87, 88, 92, 104, 106, 108, 122, 123, 124, 125]\n8\nFinal: [3, 5, 7, 34, 39, 40, 41, 51, 52, 63, 120, 121, 124]\nFinal: [0, 2, 3, 4, 5, 7, 8, 23, 26, 28, 33, 34, 39, 40, 41, 46, 48, 51, 52, 59, 63, 65, 70, 80, 87, 88, 89, 92, 104, 105, 122, 123, 124, 125]\n9\nFinal: [1, 3, 5, 7, 28, 34, 39, 41, 51, 53, 87, 104, 120, 121, 124]\nFinal: [0, 1, 2, 3, 5, 7, 8, 26, 28, 34, 39, 40, 41, 46, 48, 51, 52, 53, 63, 65, 70, 80, 87, 88, 89, 92, 104, 108, 122, 123, 124, 125]\n```\n:::\n:::\n\n\n::: {#616fc174 .cell execution_count=21}\n``` {.python .cell-code}\nprev = PREV.iloc[:,1:]\nround((prev.sub(PREV.Y, axis=0)**2).mean(),2)\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```\nY          0.00\nMCO      162.74\nBIC      163.77\nAIC      158.73\nridge    157.86\nlasso    155.43\nelast    156.55\npls      160.24\npcr      167.39\ndtype: float64\n```\n:::\n:::\n\n\n##  Modèles de prévision avec des splines et des interactions\n\n::: {#61d138de .cell execution_count=22}\n``` {.python .cell-code}\nXsplineinter = np.concatenate((Xinter[:,22:],Xspline),axis=1)\n```\n:::\n\n\n::: {#comparaison_splines_inter .cell cache='true' execution_count=23}\n``` {.python .cell-code}\nkfregul = KFold(n_splits=10, shuffle=True, random_state=0)\nkfaxes = KFold(n_splits=4, shuffle=True, random_state=0)\nnbaxes = 40\n# instanciation steps\ncr = StandardScaler()\nlassocv = LassoCV(cv=kfregul, n_jobs=3,max_iter=3000)\nenetcv = ElasticNetCV(cv=kfregul, n_jobs=3,max_iter=3000)\n# instanciation pipeline\npipe_lassocv = Pipeline(steps=[(\"cr\", cr), (\"lassocv\", lassocv)])\npipe_enetcv = Pipeline(steps=[(\"cr\", cr), (\"enetcv\", enetcv)])\n## ridge : path\netape_lasso = pipe_lassocv.named_steps[\"lassocv\"]\n# intanciations\nridge = Ridge()\npipe_ridge = Pipeline(steps=[(\"cr\", cr), (\"ridge\", ridge)])\nacp = PCA()\nreg = LinearRegression()\npipe_pcr = Pipeline(steps=[(\"cr\", cr), (\"acp\", acp), (\"reg\", reg)])\nregpls = PLSRegression()\n## grille composantes et decoupage VC\nparam_grid_pcr = { \"acp__n_components\" : list(range(1,nbaxes))}\nparam_grid_pls = { \"n_components\" : list(range(1,nbaxes))}\n \nfor i in np.arange(nb):\n    print(i)\n    Xapp = Xsplineinter[bloc!=i,:]\n    Xtest = Xsplineinter[bloc==i,:]\n    Yapp = don[bloc!=i][\"Y\"]\n    Ytest = don[bloc==i][\"Y\"]\n    #### reg\n    reg = LinearRegression()\n    reg.fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"MCO\"] = reg.predict(Xtest)\n    ### bic\n    inst_reg_bic = ols_step_sk.LinearRegressionSelectionFeatureIC(verbose=1,crit=\"bic\")\n    reg_bic = inst_reg_bic.fit(X=Xapp, y=Yapp)\n    PREV.loc[PREV.bloc==i,\"BIC\"] = reg_bic.predict(Xtest)\n    ### aic\n    inst_reg_aic = ols_step_sk.LinearRegressionSelectionFeatureIC(verbose=1,crit=\"aic\")\n    reg_aic = inst_reg_aic.fit(X=Xapp, y=Yapp)\n    PREV.loc[PREV.bloc==i,\"AIC\"] = reg_aic.predict(Xtest)\n    ## lasso\n    pipe_lassocv.fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"lasso\"] = pipe_lassocv.predict(Xtest)\n    ## elastic net\n    pipe_enetcv.fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"elast\"] = pipe_enetcv.predict(Xtest)    \n    ## params lambda\n    path_ridge = etape_lasso.alphas_ * 100    \n    param_grid_ridge = {\"ridge__alpha\": path_ridge}\n    ## GridSearchCV\n    cv_ridge = GridSearchCV(pipe_ridge, param_grid_ridge, cv=kfregul, scoring = \"neg_mean_squared_error\", n_jobs=3).fit(Xapp, Yapp)\n    PREV.loc[PREV.bloc==i,\"ridge\"] = cv_ridge.predict(Xtest)\n    ## gridsearch instanciation et fit\n    cv_pcr = GridSearchCV(pipe_pcr, param_grid_pcr, cv=kfaxes, scoring = \"neg_mean_squared_error\", n_jobs=3).fit(Xapp,Yapp)\n    cv_pls = GridSearchCV(regpls, param_grid_pls, cv=kfaxes, scoring = \"neg_mean_squared_error\", n_jobs=3).fit(Xapp,Yapp)\n    PREV.loc[PREV.bloc==i,\"pcr\"] = cv_pcr.predict(Xtest)\n    PREV.loc[PREV.bloc==i,\"pls\"] = cv_pls.predict(Xtest)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0\nFinal: [2, 79, 117, 121, 131, 211, 243, 244, 249, 313, 330]\nFinal: [2, 4, 16, 45, 76, 79, 117, 121, 128, 140, 142, 147, 158, 161, 171, 174, 181, 184, 207, 209, 216, 217, 232, 236, 243, 244, 249, 253, 257, 291, 294, 296, 297, 301, 308, 313, 329, 330, 332, 333, 334]\n1\nFinal: [5, 7, 19, 55, 76, 130, 131, 211, 243, 244, 296, 330]\nFinal: [5, 7, 8, 11, 16, 19, 25, 29, 55, 56, 66, 69, 76, 80, 86, 93, 97, 117, 118, 131, 136, 142, 143, 147, 163, 171, 174, 184, 185, 187, 211, 238, 241, 243, 245, 249, 252, 274, 276, 282, 291, 295, 296, 297, 298, 301, 308, 315, 329, 330, 333]\n2\nFinal: [6, 21, 79, 105, 117, 121, 211, 243, 250, 274, 291, 296, 297, 313, 330]\nFinal: [3, 11, 19, 37, 55, 56, 75, 95, 97, 106, 108, 109, 115, 117, 124, 128, 131, 133, 136, 142, 144, 145, 147, 171, 174, 184, 187, 204, 207, 209, 210, 211, 222, 232, 238, 241, 243, 248, 249, 250, 255, 258, 259, 266, 274, 281, 291, 293, 294, 296, 297, 298, 300, 308, 313, 330, 331, 333]\n3\nFinal: [5, 19, 25, 55, 76, 79, 108, 117, 131, 211, 243, 244, 286, 289, 296, 297, 313, 330]\nFinal: [5, 6, 16, 19, 22, 24, 36, 51, 55, 57, 59, 69, 74, 75, 94, 95, 102, 108, 109, 115, 124, 128, 130, 134, 136, 142, 145, 147, 153, 166, 170, 181, 183, 207, 209, 213, 216, 221, 223, 228, 238, 243, 245, 249, 250, 256, 261, 277, 280, 286, 291, 292, 294, 297, 298, 305, 315, 329, 330, 333]\n4\nFinal: [2, 19, 55, 79, 105, 117, 121, 211, 243, 244, 286, 289, 296, 297, 330]\nFinal: [2, 5, 15, 19, 20, 55, 63, 69, 79, 93, 115, 117, 120, 128, 136, 142, 147, 151, 165, 168, 169, 171, 184, 193, 209, 215, 216, 232, 238, 243, 244, 249, 255, 258, 259, 268, 276, 284, 286, 291, 293, 294, 296, 297, 301, 308, 311, 315, 329, 330, 333]\n5\nFinal: [6, 75, 93, 97, 105, 117, 171, 211, 216, 243, 289, 295, 297, 330]\nFinal: [2, 16, 18, 19, 21, 22, 23, 55, 56, 68, 74, 75, 81, 91, 93, 105, 115, 123, 124, 127, 128, 130, 131, 135, 142, 143, 147, 150, 155, 161, 174, 189, 196, 200, 207, 209, 213, 216, 221, 228, 232, 236, 243, 244, 248, 249, 255, 262, 267, 268, 270, 276, 289, 295, 297, 298, 301, 307, 309, 312, 313, 325, 329, 330, 333]\n6\nFinal: [19, 55, 75, 93, 97, 103, 142, 155, 211, 241, 242, 243, 289, 297, 330]\nFinal: [2, 3, 16, 19, 25, 29, 53, 55, 74, 75, 81, 86, 94, 97, 103, 130, 142, 164, 170, 184, 208, 209, 232, 238, 242, 243, 245, 248, 249, 255, 259, 274, 275, 280, 284, 291, 295, 297, 298, 301, 308, 313, 329, 330, 333]\n7\nFinal: [76, 78, 117, 120, 131, 174, 211, 216, 243, 249, 291, 296, 297, 313, 330]\nFinal: [0, 5, 31, 36, 42, 51, 55, 61, 69, 75, 81, 93, 115, 117, 120, 123, 128, 140, 142, 163, 170, 172, 174, 184, 208, 209, 216, 221, 224, 232, 238, 243, 244, 245, 249, 255, 257, 274, 289, 290, 294, 296, 297, 315, 325, 329, 330, 333]\n8\nFinal: [0, 55, 76, 93, 117, 131, 155, 211, 243, 244, 289, 296, 297, 313, 330]\nFinal: [0, 5, 6, 11, 28, 31, 34, 36, 55, 68, 76, 93, 117, 120, 122, 127, 128, 136, 142, 147, 150, 151, 164, 172, 174, 184, 187, 193, 199, 208, 209, 211, 216, 229, 232, 238, 243, 244, 245, 249, 255, 259, 274, 280, 281, 291, 295, 297, 298, 301, 309, 311, 313, 314, 329, 330, 333]\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n9\nFinal: [0, 55, 76, 94, 105, 117, 155, 211, 243, 244, 296, 297, 313, 330]\nFinal: [5, 11, 12, 16, 19, 22, 24, 25, 55, 57, 59, 68, 76, 78, 93, 100, 114, 115, 117, 120, 123, 127, 128, 142, 150, 154, 160, 168, 169, 170, 174, 176, 177, 184, 199, 207, 209, 211, 216, 231, 243, 245, 249, 255, 256, 259, 273, 275, 280, 281, 291, 294, 296, 297, 298, 301, 309, 313, 314, 329, 330, 333, 334]\n```\n:::\n:::\n\n\n::: {#b7f20535 .cell execution_count=24}\n``` {.python .cell-code}\nprev = PREV.iloc[:,1:]\nround((prev.sub(PREV.Y, axis=0)**2).mean(),2)\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```\nY          0.00\nMCO      193.29\nBIC      153.88\nAIC      164.73\nridge    156.45\nlasso    154.41\nelast    154.17\npls      160.23\npcr      164.32\ndtype: float64\n```\n:::\n:::\n\n\n",
    "supporting": [
      "chap11_files"
    ],
    "filters": [],
    "includes": {}
  }
}